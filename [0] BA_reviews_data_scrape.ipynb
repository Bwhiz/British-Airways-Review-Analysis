{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89565ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e51a6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.airlinequality.com/airline-reviews/british-airways/page/'\n",
    "page_size = '/?sortby=post_date%3ADesc&pagesize=100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ebc7642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ scraping page 1 --------\n",
      "100 of review_headers has been scraped so far\n",
      "100 of reviews has been scraped\n",
      "100 of time info scraped\n",
      "------ scraping page 2 --------\n",
      "200 of review_headers has been scraped so far\n",
      "200 of reviews has been scraped\n",
      "200 of time info scraped\n",
      "------ scraping page 3 --------\n",
      "300 of review_headers has been scraped so far\n",
      "300 of reviews has been scraped\n",
      "300 of time info scraped\n",
      "------ scraping page 4 --------\n",
      "400 of review_headers has been scraped so far\n",
      "400 of reviews has been scraped\n",
      "400 of time info scraped\n",
      "------ scraping page 5 --------\n",
      "500 of review_headers has been scraped so far\n",
      "500 of reviews has been scraped\n",
      "500 of time info scraped\n",
      "------ scraping page 6 --------\n",
      "600 of review_headers has been scraped so far\n",
      "600 of reviews has been scraped\n",
      "600 of time info scraped\n",
      "------ scraping page 7 --------\n",
      "700 of review_headers has been scraped so far\n",
      "700 of reviews has been scraped\n",
      "700 of time info scraped\n",
      "------ scraping page 8 --------\n",
      "800 of review_headers has been scraped so far\n",
      "800 of reviews has been scraped\n",
      "800 of time info scraped\n",
      "------ scraping page 9 --------\n",
      "900 of review_headers has been scraped so far\n",
      "900 of reviews has been scraped\n",
      "900 of time info scraped\n",
      "------ scraping page 10 --------\n",
      "1000 of review_headers has been scraped so far\n",
      "1000 of reviews has been scraped\n",
      "1000 of time info scraped\n",
      "------ scraping page 11 --------\n",
      "1100 of review_headers has been scraped so far\n",
      "1100 of reviews has been scraped\n",
      "1100 of time info scraped\n",
      "------ scraping page 12 --------\n",
      "1200 of review_headers has been scraped so far\n",
      "1200 of reviews has been scraped\n",
      "1200 of time info scraped\n",
      "------ scraping page 13 --------\n",
      "1300 of review_headers has been scraped so far\n",
      "1300 of reviews has been scraped\n",
      "1300 of time info scraped\n",
      "------ scraping page 14 --------\n",
      "1400 of review_headers has been scraped so far\n",
      "1400 of reviews has been scraped\n",
      "1400 of time info scraped\n",
      "------ scraping page 15 --------\n",
      "1500 of review_headers has been scraped so far\n",
      "1500 of reviews has been scraped\n",
      "1500 of time info scraped\n",
      "------ scraping page 16 --------\n",
      "1600 of review_headers has been scraped so far\n",
      "1600 of reviews has been scraped\n",
      "1600 of time info scraped\n",
      "------ scraping page 17 --------\n",
      "1700 of review_headers has been scraped so far\n",
      "1700 of reviews has been scraped\n",
      "1700 of time info scraped\n",
      "------ scraping page 18 --------\n",
      "1800 of review_headers has been scraped so far\n",
      "1800 of reviews has been scraped\n",
      "1800 of time info scraped\n",
      "------ scraping page 19 --------\n",
      "1900 of review_headers has been scraped so far\n",
      "1900 of reviews has been scraped\n",
      "1900 of time info scraped\n",
      "------ scraping page 20 --------\n",
      "2000 of review_headers has been scraped so far\n",
      "2000 of reviews has been scraped\n",
      "2000 of time info scraped\n",
      "------ scraping page 21 --------\n",
      "2100 of review_headers has been scraped so far\n",
      "2100 of reviews has been scraped\n",
      "2100 of time info scraped\n",
      "------ scraping page 22 --------\n",
      "2200 of review_headers has been scraped so far\n",
      "2200 of reviews has been scraped\n",
      "2200 of time info scraped\n",
      "------ scraping page 23 --------\n",
      "2300 of review_headers has been scraped so far\n",
      "2300 of reviews has been scraped\n",
      "2300 of time info scraped\n",
      "------ scraping page 24 --------\n",
      "2400 of review_headers has been scraped so far\n",
      "2400 of reviews has been scraped\n",
      "2400 of time info scraped\n",
      "------ scraping page 25 --------\n",
      "2500 of review_headers has been scraped so far\n",
      "2500 of reviews has been scraped\n",
      "2500 of time info scraped\n",
      "------ scraping page 26 --------\n",
      "2600 of review_headers has been scraped so far\n",
      "2600 of reviews has been scraped\n",
      "2600 of time info scraped\n",
      "------ scraping page 27 --------\n",
      "2700 of review_headers has been scraped so far\n",
      "2700 of reviews has been scraped\n",
      "2700 of time info scraped\n",
      "------ scraping page 28 --------\n",
      "2800 of review_headers has been scraped so far\n",
      "2800 of reviews has been scraped\n",
      "2800 of time info scraped\n",
      "------ scraping page 29 --------\n",
      "2900 of review_headers has been scraped so far\n",
      "2900 of reviews has been scraped\n",
      "2900 of time info scraped\n",
      "------ scraping page 30 --------\n",
      "3000 of review_headers has been scraped so far\n",
      "3000 of reviews has been scraped\n",
      "3000 of time info scraped\n",
      "------ scraping page 31 --------\n",
      "3100 of review_headers has been scraped so far\n",
      "3100 of reviews has been scraped\n",
      "3100 of time info scraped\n",
      "------ scraping page 32 --------\n",
      "3200 of review_headers has been scraped so far\n",
      "3200 of reviews has been scraped\n",
      "3200 of time info scraped\n",
      "------ scraping page 33 --------\n",
      "3300 of review_headers has been scraped so far\n",
      "3300 of reviews has been scraped\n",
      "3300 of time info scraped\n",
      "------ scraping page 34 --------\n",
      "3400 of review_headers has been scraped so far\n",
      "3400 of reviews has been scraped\n",
      "3400 of time info scraped\n",
      "------ scraping page 35 --------\n",
      "3500 of review_headers has been scraped so far\n",
      "3500 of reviews has been scraped\n",
      "3500 of time info scraped\n",
      "------ scraping page 36 --------\n",
      "3531 of review_headers has been scraped so far\n",
      "3531 of reviews has been scraped\n",
      "3531 of time info scraped\n"
     ]
    }
   ],
   "source": [
    "total_reviews = 36\n",
    "\n",
    "review_header = []\n",
    "review = []\n",
    "time_of_review = []\n",
    "\n",
    "for i in range(1,total_reviews+1):\n",
    "    \n",
    "    print(f'------ scraping page {i} --------')\n",
    "    \n",
    "    url = base_url + str(i) + page_size\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    content = response.content\n",
    "    \n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    #scrpae review header\n",
    "    for sub in parsed_content.find_all(\"h2\", {\"class\": \"text_header\"}):\n",
    "        review_header.append(sub.get_text())\n",
    "    #scrape review content    \n",
    "    for sub in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        review.append(sub.get_text())\n",
    "     #scrape review time\n",
    "    for sub in parsed_content.find_all(\"time\", {\"datetime\": True }):\n",
    "        time_of_review.append(sub.get_text())\n",
    "    \n",
    "    \n",
    "    print(f'{len(review_header)} of review_headers has been scraped so far\\n{len(review)} of reviews has been scraped\\n{len(time_of_review)} of time info scraped')\n",
    "    \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "101ea616",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['review_headers','reviews'])\n",
    "df['review_headers'] = review_header\n",
    "df['reviews'] = review\n",
    "df['time'] = time_of_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94f5e578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headers</th>\n",
       "      <th>reviews</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"It was a nightmare\"</td>\n",
       "      <td>Not Verified |  They changed our Flights from ...</td>\n",
       "      <td>18th April 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Abysmal service\"</td>\n",
       "      <td>Not Verified |  At Copenhagen the most chaotic...</td>\n",
       "      <td>18th April 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"trained to give you the runaround\"</td>\n",
       "      <td>✅ Trip Verified |  Worst experience of my life...</td>\n",
       "      <td>17th April 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"they only had one choice of meal\"</td>\n",
       "      <td>✅ Trip Verified |  Due to code sharing with Ca...</td>\n",
       "      <td>17th April 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"relentless BA cost cutting\"</td>\n",
       "      <td>✅ Trip Verified |  LHR check in was quick at t...</td>\n",
       "      <td>16th April 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>British Airways customer review</td>\n",
       "      <td>YYZ to LHR - July 2012 - I flew overnight in p...</td>\n",
       "      <td>29th August 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>British Airways customer review</td>\n",
       "      <td>LHR to HAM. Purser addresses all club passenge...</td>\n",
       "      <td>28th August 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>British Airways customer review</td>\n",
       "      <td>My son who had worked for British Airways urge...</td>\n",
       "      <td>12th October 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>British Airways customer review</td>\n",
       "      <td>London City-New York JFK via Shannon on A318 b...</td>\n",
       "      <td>11th October 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>British Airways customer review</td>\n",
       "      <td>SIN-LHR BA12 B747-436 First Class. Old aircraf...</td>\n",
       "      <td>9th October 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3531 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           review_headers  \\\n",
       "0                    \"It was a nightmare\"   \n",
       "1                       \"Abysmal service\"   \n",
       "2     \"trained to give you the runaround\"   \n",
       "3      \"they only had one choice of meal\"   \n",
       "4            \"relentless BA cost cutting\"   \n",
       "...                                   ...   \n",
       "3526      British Airways customer review   \n",
       "3527      British Airways customer review   \n",
       "3528      British Airways customer review   \n",
       "3529      British Airways customer review   \n",
       "3530      British Airways customer review   \n",
       "\n",
       "                                                reviews               time  \n",
       "0     Not Verified |  They changed our Flights from ...    18th April 2023  \n",
       "1     Not Verified |  At Copenhagen the most chaotic...    18th April 2023  \n",
       "2     ✅ Trip Verified |  Worst experience of my life...    17th April 2023  \n",
       "3     ✅ Trip Verified |  Due to code sharing with Ca...    17th April 2023  \n",
       "4     ✅ Trip Verified |  LHR check in was quick at t...    16th April 2023  \n",
       "...                                                 ...                ...  \n",
       "3526  YYZ to LHR - July 2012 - I flew overnight in p...   29th August 2012  \n",
       "3527  LHR to HAM. Purser addresses all club passenge...   28th August 2012  \n",
       "3528  My son who had worked for British Airways urge...  12th October 2011  \n",
       "3529  London City-New York JFK via Shannon on A318 b...  11th October 2011  \n",
       "3530  SIN-LHR BA12 B747-436 First Class. Old aircraf...   9th October 2011  \n",
       "\n",
       "[3531 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c5195af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 'data' directory\n",
    "os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe7895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/BA_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40cc9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
